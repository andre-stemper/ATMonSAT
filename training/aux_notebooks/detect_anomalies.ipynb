{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Copyright 2022 University of Luxembourg\n",
    "> \n",
    "> Licensed under the Apache License, Version 2.0 (the \"License\");  \n",
    "> you may not use this file except in compliance with the License.  \n",
    "> You may obtain a copy of the License at  \n",
    ">\n",
    ">    https://www.apache.org/licenses/LICENSE-2.0\n",
    ">\n",
    "> Unless required by applicable law or agreed to in writing, software  \n",
    "> distributed under the License is distributed on an \"AS IS\" BASIS,  \n",
    "> WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  \n",
    "> See the License for the specific language governing permissions and  \n",
    "> limitations under the License.  \n",
    ">\n",
    "***\n",
    "\n",
    "Author: Andrzej Mizera (andrzej.mizera@uni.lu)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Called by the AtMonSat anomaly detection algorithm to compute prediction errors for individual abnormal datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "islc_abnorm = getIterationsSinceLastChangeMicro(abnormal_df,abnormal_features)\n",
    "df_abnorm_values = pd.DataFrame(islc_abnorm)\n",
    "feature_abnorm_values = abnormal_df[abnormal_features].astype('float32').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInterpolationInfo(df,features):\n",
    "    \n",
    "    fs = list(features) \n",
    "\n",
    "    num_iterations_since_last_change_vec = np.zeros(len(fs),np.float32)\n",
    "    \n",
    "    list_of_num_iterations_since_last_change = [num_iterations_since_last_change_vec.tolist()]\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    while (i+1 < len(df.index)):\n",
    "        \n",
    "        next_num_iterations_since_last_change_vec = np.zeros(len(fs),np.float32)\n",
    "        \n",
    "        features_to_interpolate = []    \n",
    "        for f_ind,f in enumerate(fs):\n",
    "            \n",
    "            if (df[f].iat[i] == df[f].iat[i+1]):\n",
    "                next_num_iterations_since_last_change_vec[f_ind] = num_iterations_since_last_change_vec[f_ind] + 1\n",
    "            else:\n",
    "                features_to_interpolate.append(f_ind)\n",
    "         \n",
    "        list_of_num_iterations_since_last_change.append(next_num_iterations_since_last_change_vec.tolist())\n",
    "        \n",
    "        # If any of the features changed\n",
    "        if len(features_to_interpolate) > 0:\n",
    "\n",
    "            # Number of iterations back to previous change \n",
    "            nilc = int(min(num_iterations_since_last_change_vec)) + 1\n",
    "            \n",
    "            result.append((i+1,nilc))\n",
    "\n",
    "        num_iterations_since_last_change_vec = next_num_iterations_since_last_change_vec\n",
    "        \n",
    "        i = i + 1\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of temperature change datapoint and the number of datapoints since previous temperature change.\n",
    "# Returns a dictionary with t_anomalies as keys and pairs of anomaly index and the detection margin before\n",
    "# anomaly.\n",
    "def getInterpolationInfoForAnomalies(df,features,t_anomalies):\n",
    "    \n",
    "    interpInfo = getInterpolationInfo(df,features)\n",
    "    \n",
    "    InterpInfoForAnomalies = {}\n",
    "    \n",
    "    for t_anomaly in t_anomalies:\n",
    "        \n",
    "        ind_anomaly = list(df.index >= t_anomaly).index(True)\n",
    "\n",
    "        for entry in interpInfo:\n",
    "            if (entry[0] >= ind_anomaly):\n",
    "                \n",
    "                # c x x x x x a x x x c\n",
    "                # c- change, x - no change, a - anomaly\n",
    "                ind_first_change_after_anomaly = entry[0]\n",
    "                detection_margin_before_anomaly = entry[1] - (entry[0] - ind_anomaly) - 1\n",
    "                \n",
    "                assert detection_margin_before_anomaly >= 0\n",
    "                \n",
    "                InterpInfoForAnomalies[t_anomaly] = (ind_anomaly,detection_margin_before_anomaly)\n",
    "                \n",
    "                break\n",
    "    \n",
    "    return InterpInfoForAnomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Preparation of the data for anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if (model_name == 'AutoEncoder'):\n",
    "\n",
    "    _, _, X_abnorm, Y_abnorm = create_subseq_AE(np.append(df_abnorm_values,feature_abnorm_values,axis=1), window_length)\n",
    "    \n",
    "elif (model_name == 'CNN') or (model_name == 'LSTM') or (model_name == 'LSTM_2'):\n",
    "\n",
    "    _, _, X_abnorm, Y_abnorm = create_subseq(np.append(df_abnorm_values,feature_abnorm_values,axis=1), np.append(df_abnorm_values,feature_abnorm_values,axis=1), window_length, 1)\n",
    "\n",
    "else:\n",
    "    raise ValueError('Wrong model name!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation of the prediction errors on the test data subset, i.e., test errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cet_abnorm = abnormal_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(np.array(X_abnorm))\n",
    "    \n",
    "pred_np = pred.numpy()\n",
    "if (len(pred_np.shape) == 2):\n",
    "    pred_np = np.expand_dims(pred_np,axis=1)\n",
    "    \n",
    "te = pred_np - np.array(Y_abnorm)\n",
    "\n",
    "test_errors = np.reshape(te,(te.shape[0],te.shape[1]*te.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding = np.zeros(window_length)\n",
    "\n",
    "def score(x):\n",
    "    if not kPCA:\n",
    "        pca_variances = pca.explained_variance_[first_higher_order_PCA:]\n",
    "    else:\n",
    "        pca_variances = pca.lambdas_[first_higher_order_PCA:]\n",
    "    #return sum(np.divide(np.square(x),np.tile(pca_variances,window_length)))\n",
    "    return sum(np.divide(np.square(x),pca_variances))\n",
    "\n",
    "def vec_length(x):\n",
    "    return np.sqrt(sum(np.square(x)))\n",
    "\n",
    "if PCA_higher_order_analysis:\n",
    "    error_fun = score\n",
    "else:\n",
    "    error_fun = vec_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = plt.rcParams.get('font.size')\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "figure(figsize=(20, 7))\n",
    "if DeltaLastChangeTimes_analysis:\n",
    "    plt.plot(cet_abnorm,\n",
    "             np.concatenate((padding,np.apply_along_axis(error_fun, 1, test_errors))),\n",
    "             color='r', label='Euclidean error'\n",
    "            )\n",
    "else:\n",
    "    plt.plot(np.concatenate((padding,np.apply_along_axis(error_fun, 1, test_errors))),\n",
    "             color='r', label='Euclidean error'\n",
    "            )\n",
    "plt.xlabel('Timestamp [Month-Day Hour]')\n",
    "plt.ylabel('Euclidean error')\n",
    "\n",
    "if len(anomaly_times) > 0:\n",
    "    if DeltaLastChangeTimes_analysis:\n",
    "        plt.vlines(t_anomalies,0,max(np.apply_along_axis(error_fun, 1, test_errors)),color=ANOMALY_COLOR)\n",
    "    else:\n",
    "        ind_anomalies = [list(abnormal_df_full.index >= t_anomaly).index(True) for t_anomaly in t_anomalies]\n",
    "        plt.vlines(ind_anomalies,0,max(np.apply_along_axis(error_fun, 1, test_errors)),color=ANOMALY_COLOR)\n",
    "\n",
    "if DeltaLastChangeTimes_analysis:\n",
    "    plt.hlines(error_threshold,cet_abnorm[0],cet_abnorm[-1],'g','dashed')\n",
    "else:\n",
    "    plt.hlines(error_threshold,ind_anomalies[0],ind_anomalies[-1],'g','dashed')\n",
    "\n",
    "plot_file_name = os.path.join(output_folder,'error_' + anomaly_ds + '.pdf')\n",
    "plt.savefig(plot_file_name, format='pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "plt.show()\n",
    "plt.rcParams.update({'font.size': fs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the Mahalanobis distances for the prediction errors on the test data subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calculate Mahalanobis distance\n",
    "def Mahala_distance(x,mean,cov):\n",
    "    d = np.dot(x-mean,np.linalg.inv(cov))\n",
    "    d = np.dot(d, (x-mean).T)\n",
    "    return d\n",
    "\n",
    "m_dist = [0]*window_length \n",
    "for e in test_errors:\n",
    "    m_dist.append(Mahala_distance(e,mean,cov))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Mahalanobis distance for the test dataset predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.dates import DateFormatter\n",
    "\n",
    "fs = plt.rcParams.get('font.size')\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "figure(figsize=(20, 7))\n",
    "if DeltaLastChangeTimes_analysis:\n",
    "    plt.plot(cet_abnorm, m_dist, color='r', label='Mahalanobis Distance')\n",
    "else:\n",
    "    plt.plot(m_dist, color='r', label='Mahalanobis Distance')\n",
    "\n",
    "plt.ylabel('Mahalanobis error')\n",
    "\n",
    "if len(anomaly_times) > 0:\n",
    "    if DeltaLastChangeTimes_analysis:\n",
    "        plt.vlines(t_anomalies,0,max(m_dist),colors=ANOMALY_COLOR)\n",
    "    else:\n",
    "        ind_anomalies = [list(abnormal_df_full.index >= t_anomaly).index(True) for t_anomaly in t_anomalies]\n",
    "        plt.vlines(ind_anomalies,0,max(m_dist),colors=ANOMALY_COLOR)\n",
    "\n",
    "if DeltaLastChangeTimes_analysis:\n",
    "    plt.hlines(mahalanobis_error_threshold,cet_abnorm[0],cet_abnorm[-1],'g','dashed',\n",
    "               label='Mahalanobis error threshold')\n",
    "else:\n",
    "    plt.hlines(mahalanobis_error_threshold,ind_anomalies[0],ind_anomalies[-1],'g','dashed',\n",
    "               label='Mahalanobis error threshold')\n",
    "\n",
    "date_form = DateFormatter(\"%H:%M\")\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(date_form)\n",
    "\n",
    "plot_file_name = os.path.join(output_folder,'mahalanobis_error_' + anomaly_ds + '.pdf')\n",
    "plt.savefig(plot_file_name, format='pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "plt.show()\n",
    "plt.rcParams.update({'font.size': fs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
