{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60cd24a2",
   "metadata": {},
   "source": [
    "> Copyright 2022 University of Luxembourg\n",
    "> \n",
    "> Licensed under the Apache License, Version 2.0 (the \"License\");  \n",
    "> you may not use this file except in compliance with the License.  \n",
    "> You may obtain a copy of the License at  \n",
    ">\n",
    ">    https://www.apache.org/licenses/LICENSE-2.0\n",
    ">\n",
    "> Unless required by applicable law or agreed to in writing, software  \n",
    "> distributed under the License is distributed on an \"AS IS\" BASIS,  \n",
    "> WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  \n",
    "> See the License for the specific language governing permissions and  \n",
    "> limitations under the License.  \n",
    ">\n",
    "***\n",
    "\n",
    "Author: Andrzej Mizera (andrzej.mizera@uni.lu)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed407ee",
   "metadata": {},
   "source": [
    "# Auxiliary functions used by the AtMonSat anomaly detection algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b82fd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f7296e",
   "metadata": {},
   "source": [
    "---\n",
    "### For the computation of the Interpolated Iterations Since Last Change (IISLC) features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1995f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInterpolationValues(start_value,num_iterations):\n",
    "    flin = interpolate.interp1d([0,num_iterations], [start_value,0])\n",
    "    \n",
    "    if (ISLC_implementation == 'uint32'):\n",
    "        return flin(np.arange(1, num_iterations, 1)).astype('uint32').astype('float32')\n",
    "\n",
    "    return flin(np.arange(1, num_iterations, 1)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a307767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIterationsSinceLastChangeMicro(df,features,updated=False):\n",
    "    \n",
    "    fs = list(features) \n",
    "\n",
    "    num_iterations_since_last_change_vec = np.zeros(len(fs),np.float32)\n",
    "    \n",
    "    list_of_num_iterations_since_last_change = [num_iterations_since_last_change_vec.tolist()]\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    while (i+1 < len(df.index)):\n",
    "        \n",
    "        next_num_iterations_since_last_change_vec = np.zeros(len(fs),np.float32)\n",
    "        \n",
    "        features_to_interpolate = []    \n",
    "        for f_ind,f in enumerate(fs):\n",
    "            \n",
    "            if (df[f].iat[i] == df[f].iat[i+1]):\n",
    "                next_num_iterations_since_last_change_vec[f_ind] = num_iterations_since_last_change_vec[f_ind] + 1\n",
    "            else:\n",
    "                features_to_interpolate.append(f_ind)\n",
    "         \n",
    "        list_of_num_iterations_since_last_change.append(next_num_iterations_since_last_change_vec.tolist())\n",
    "        \n",
    "        # Perform interpolation\n",
    "        #print(features_to_interpolate)\n",
    "        for f_ind in features_to_interpolate:\n",
    "            \n",
    "            # Number of iterations back to previous change \n",
    "            nilc = int(min(num_iterations_since_last_change_vec)) + 1\n",
    "#            nilc_list.append(nilc)\n",
    "\n",
    "            if updated:\n",
    "                \n",
    "                interp_start_value = list_of_num_iterations_since_last_change[-1-nilc][f_ind]\n",
    "                \n",
    "                if (interp_start_value == 0):\n",
    "                \n",
    "                    interp_start_value = num_iterations_since_last_change_vec[f_ind] + 1\n",
    "                \n",
    "                interp_vals = getInterpolationValues(interp_start_value,nilc)\n",
    "                \n",
    "            else:\n",
    "            \n",
    "                interp_vals = getInterpolationValues(list_of_num_iterations_since_last_change[-1-nilc][f_ind],nilc)\n",
    "            \n",
    "            for interp_val_ind, interp_val in enumerate(interp_vals):\n",
    "                list_of_num_iterations_since_last_change[-nilc+interp_val_ind][f_ind] = interp_val\n",
    "\n",
    "        num_iterations_since_last_change_vec = next_num_iterations_since_last_change_vec\n",
    "        \n",
    "        i = i + 1\n",
    "        \n",
    "    return np.asarray(list_of_num_iterations_since_last_change,np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159355b5",
   "metadata": {},
   "source": [
    "---\n",
    "### For splitting time-series data into input-ouput pairs for model training, validation, and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65038d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subsequences of the \"look_back\" length from time-series, \"ts_in\" and \"ts_out\"\n",
    "# and the next \"pred_length\" values as labels.\n",
    "def create_subseq(ts_in, ts_out, look_back, pred_length, features=None):\n",
    "    \n",
    "    sub_seq, next_values = [], []\n",
    "    for i in range(len(ts_in)-look_back-pred_length+1):  \n",
    "        sub_seq.append(ts_in[i:i+look_back])\n",
    "        if features is not None:\n",
    "            next_values.append(ts_out[i+look_back:i+look_back+pred_length,features])\n",
    "        else:\n",
    "            next_values.append(ts_out[i+look_back:i+look_back+pred_length])\n",
    "    \n",
    "    return (ts_in.shape[1], ts_out.shape[1], np.array(sub_seq), np.array(next_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf3e47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the AutoEncoder model\n",
    "def create_subseq_AE(ts_in, look_back, features=None):\n",
    "    _l = len(ts_in)\n",
    "    \n",
    "    Xs = []\n",
    "    Ys = []\n",
    "\n",
    "    # For an autoencoder - Ys are the same as Xs. There is no need to pull the next sequence of values!\n",
    "    for i in range(0, (_l - look_back)):\n",
    "        Xs.append(ts_in[i:i+look_back])\n",
    "        if features is not None:\n",
    "            Ys.append(ts_in[i:i+look_back,features])\n",
    "        else:\n",
    "            Ys.append(ts_in[i:i+look_back])\n",
    "        \n",
    "    return (ts_in.shape[1], ts_in.shape[1], np.array(Xs), np.array(Ys))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1368a4d",
   "metadata": {},
   "source": [
    "---\n",
    "### Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29475698",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PCA_higher_order_analysis:\n",
    "    if not kPCA:\n",
    "        pca_variances = pca.explained_variance_[first_higher_order_PCA:]\n",
    "    else:\n",
    "        pca_variances = pca.lambdas_[first_higher_order_PCA:]\n",
    "\n",
    "    pca_variances = tf.constant(pca_variances,dtype=tf.float32)\n",
    "\n",
    "    def pca_score_error(y_true, y_pred):\n",
    "        \n",
    "        y_pred = tf.convert_to_tensor(y_pred)\n",
    "        y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    \n",
    "        return tf.math.reduce_sum(tf.math.divide(tf.math.square(y_true - y_pred),pca_variances))\n",
    "    \n",
    "    loss_fun = pca_score_error\n",
    "\n",
    "else:\n",
    "\n",
    "    def vec_length_error(y_true, y_pred):\n",
    "        y_pred = tf.convert_to_tensor(y_pred)\n",
    "        y_true = tf.cast(y_true, y_pred.dtype)\n",
    "\n",
    "        return tf.math.sqrt(tf.math.reduce_sum(tf.math.square(y_pred - y_true)))\n",
    "\n",
    "    loss_fun = vec_length_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c92499e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
