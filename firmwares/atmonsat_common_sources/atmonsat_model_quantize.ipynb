{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Copyright 2022 University of Luxembourg\n",
    "> \n",
    "> Licensed under the Apache License, Version 2.0 (the \"License\");  \n",
    "> you may not use this file except in compliance with the License.  \n",
    "> You may obtain a copy of the License at  \n",
    ">\n",
    ">    https://www.apache.org/licenses/LICENSE-2.0\n",
    ">\n",
    "> Unless required by applicable law or agreed to in writing, software  \n",
    "> distributed under the License is distributed on an \"AS IS\" BASIS,  \n",
    "> WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  \n",
    "> See the License for the specific language governing permissions and  \n",
    "> limitations under the License.  \n",
    ">\n",
    "***\n",
    "\n",
    "Author: Andr√© Stemper (andre.stemper@uni.lu)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l_-wmxvyP73e"
   },
   "source": [
    "# Quantize model to tflite model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save a model use:\n",
    "model.save(\"model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "axunt9z5QBCr"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7rcPcaSGQWvH"
   },
   "outputs": [],
   "source": [
    "tf_model_filename = \"atmonsat_model.h5\"  # name of the keras model to load\n",
    "tf_lite_model_filename = \"atmonsat_model.tflite\"  # name of the .tflite model\n",
    "cc_header_filename = \"atmonsat_model.h\"  # cc header file\n",
    "cc_source_filename = \"atmonsat_model.cc\"  # cc implementation\n",
    "guard_name = \"ATMONSAT_MODEL\"  # name of the header guard\n",
    "variable_name = \"atmonsat_model\" # name of the variable that points to the model data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading keras model: {}\".format(tf_model_filename))\n",
    "print(\"Converting to tflite model: {}\".format(tf_lite_model_filename))\n",
    "print(\"Converting to cc source file: {}\".format(cc_source_filename))\n",
    "print(\"Converting to cc header file: {}\".format(cc_header_filename))\n",
    "print(\"Header guard: __{}_H__\".format(guard_name))\n",
    "print(\"Variable to access the tflite model: {}\".format(variable_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tf_model_filename):\n",
    "    raise FileExistsError(\n",
    "        \"Cannot find TF model file {}. Aborting.\".format(tf_model_filename))\n",
    "model = tf.keras.models.load_model(tf_model_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "2PEmqpDChct3",
    "outputId": "ad66d839-19f4-41b0-bb38-d9be838f0085"
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "print(model.input.shape)\n",
    "print(model.output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to tflite model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_profile = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load calibration tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'calibration_tensor.npy'\n",
    "calibration_input = np.load(filename)\n",
    "print(calibration_input.shape)\n",
    "np.max(np.amax(calibration_input, axis=0), axis=0)\n",
    "print(calibration_input[200, 0, :])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default quantization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DvyeXXngioVI",
    "outputId": "5a40a02f-508c-4d0e-f27b-bb373301b634"
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tf_lite_model = converter.convert()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze mode after quantization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.lite.experimental.Analyzer.analyze(model_content=tf_lite_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate model outputs for calibration data with non-quantized model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_plot_range = range(4)\n",
    "test_scale = (-500, 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'calibration_input' in locals():\n",
    "    calibration_output = model(np.array(calibration_input))\n",
    "    print(calibration_output[0, :])\n",
    "\n",
    "    for i in test_plot_range:\n",
    "        plt.ylim(test_scale)\n",
    "        plt.plot(calibration_output[:, i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate model outputs for calibration data with quantized model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'calibration_input' in locals():\n",
    "    interpreter = tf.lite.Interpreter(model_content=tf_lite_model)\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_scale = input_details[0]['quantization'][0]\n",
    "    input_zero_point = input_details[0]['quantization'][1]\n",
    "    output_scale = output_details[0]['quantization'][0]\n",
    "    output_zero_point = output_details[0]['quantization'][1]\n",
    "\n",
    "    quantized_model_outputs = []\n",
    "\n",
    "    for input_unscaled in calibration_input:\n",
    "        if quantization_profile == 2:\n",
    "            input_scaled = np.array(\n",
    "                (input_unscaled / input_scale) + input_zero_point, dtype=np.int8).reshape(1, 150, 18)\n",
    "        elif quantization_profile == 3:\n",
    "            input_scaled = np.array(\n",
    "                (input_unscaled / input_scale) + input_zero_point, dtype=np.uint8).reshape(1, 150, 18)\n",
    "        else:\n",
    "            input_scaled = np.array(\n",
    "                input_unscaled, dtype=np.float32).reshape(1, 150, 18)\n",
    "\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_scaled)\n",
    "        interpreter.invoke()\n",
    "        output_scaled = interpreter.get_tensor(output_details[0]['index'])\n",
    "        if (quantization_profile == 2) or (quantization_profile == 3):\n",
    "            output_unscaled = (\n",
    "                output_scaled - output_zero_point) * output_scale\n",
    "        else:\n",
    "            output_unscaled = output_scaled\n",
    "        quantized_model_outputs.append(output_unscaled[0])\n",
    "\n",
    "    quantized_model_outputs = np.array(quantized_model_outputs)\n",
    "\n",
    "    print(quantized_model_outputs.shape)\n",
    "    print(quantized_model_outputs[0, :])\n",
    "\n",
    "    for i in test_plot_range:\n",
    "        plt.ylim(test_scale)\n",
    "        plt.plot(quantized_model_outputs[:, i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'calibration_input' in locals():\n",
    "    for i in range(1):\n",
    "        plt.plot(np.abs(quantized_model_outputs[:, i]-calibration_output[:, i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to .tflite file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tf_lite_model_filename, 'wb') as file:\n",
    "    file.write(tf_lite_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to C header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copyright=\"\"\"/*\n",
    " Copyright 2022 University of Luxembourg\n",
    "\n",
    " Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    " you may not use this file except in compliance with the License.\n",
    " You may obtain a copy of the License at\n",
    "\n",
    "      https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    " Unless required by applicable law or agreed to in writing, software\n",
    " distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    " WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    " See the License for the specific language governing permissions and\n",
    " limitations under the License.\n",
    "*/\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e1cX-L0wi7f8"
   },
   "outputs": [],
   "source": [
    "def to_chunks(hex_data, characters_per_line=80, characters_per_value=6):\n",
    "    values_per_line = int(characters_per_line / characters_per_value)\n",
    "    return '  '+',\\n  '.join([', '.join(hex_data[i:i + values_per_line]) for i in range(0, len(hex_data), values_per_line)])\n",
    "\n",
    "\n",
    "def to_cc(data, header_filename, guard_name, variable_name):\n",
    "    global copyright\n",
    "    lines = copyright.splitlines()\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"#include <cstdint>\")\n",
    "    lines.append(\"#include <{}>\".format(header_filename))\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"/**\")\n",
    "    lines.append(\" * @brief Quantized tensorflow lite model size in bytes\")\n",
    "    lines.append(\" */\")\n",
    "    lines.append(\"const uint32_t {}_size = {};\".format(\n",
    "        variable_name, str(len(data))))\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"/**\")\n",
    "    lines.append(\" * @brief Quantized tensorflow lite model\")\n",
    "    lines.append(\" */\")\n",
    "    lines.append(\"alignas(16) const uint8_t {}[] = {{\".format(variable_name))\n",
    "    lines.append(to_chunks([format(v, '#04x') for v in data]))\n",
    "    lines.append(\"};\")\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "\n",
    "def to_h(data, guard_name, variable_name):\n",
    "    global copyright\n",
    "    lines = copyright.splitlines()\n",
    "    lines.append(\"#ifndef __{}_H__\".format(guard_name.upper()))\n",
    "    lines.append(\"#define __{}_H__\".format(guard_name.upper()))\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"#include <cstdint>\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"#ifdef __cplusplus\")\n",
    "    lines.append(\"extern \\\"C\\\"\")\n",
    "    lines.append(\"{\")\n",
    "    lines.append(\"#endif\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"/**\")\n",
    "    lines.append(\" * @brief Quantized tensorflow lite model size in bytes\")\n",
    "    lines.append(\" */\")\n",
    "    lines.append(\"extern const uint32_t {}_size;\".format(variable_name))\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"/**\")\n",
    "    lines.append(\" * @brief Quantized tensorflow lite model\")\n",
    "    lines.append(\" */\")\n",
    "    lines.append(\"extern const uint8_t {}[];\".format(variable_name))\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"#ifdef __cplusplus\")\n",
    "    lines.append(\"}\")\n",
    "    lines.append(\"#endif\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"#endif\")\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "\n",
    "with open(cc_source_filename, 'w') as file:\n",
    "    file.write(to_cc(tf_lite_model, cc_header_filename,\n",
    "               guard_name, variable_name))\n",
    "\n",
    "with open(cc_header_filename, 'w') as file:\n",
    "    file.write(to_h(tf_lite_model, guard_name, variable_name))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "tflite-sinewave-training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
